
/*
搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查
询串的长度为1-255字节。假设目前一个日志文件中有一千万个记录（这些查询
串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。
一个查询串的重复度越高，说明查询它的用户越多，也就是越热门），请你统计
最热门的10个查询串，要求使用的内存不能超过1G。
1000万条记录，每条记录最大为255Byte，那么日志文件最大有2.5G左右，大于1G内存。
但是题目中又提到这样的1000万条记录中有许多是重复的，出去重复的话只有300万条记
录，存储这样的300万条记录需要0.75G左右的内存，小于1G内存。那么我们可以考虑将


这些无重复的记录装入内存，这是我们需要一种数据结构，这种数据结构即能够存储查询串，
又能存储查询串的出现次数，我们可以通过hashmap<query,count>来保存。读取文件，创建
一个hashmap，如果hashmap中存储了遍历到的query，则修改该query所对应的count值，
使其+1；如果hashmap中没有这个query，那么往haspmap中插入<query,1>。这样我们就创
建好了一个包含所有query和次数的hashmap。
然后我们创建一个长度为10最大堆MaxHeap，遍历hashmap，如果MaxHeap未满，那么往
MaxHeap中插入这个键值对，如果MinHeap满了，则比较遍历到的元素的count值堆顶的
count，如果遍历到元素的count大于堆顶count值，删除堆顶元素，插入当前遍历到的元素。
遍历完整个hashmap以后，在MaxHeap中存储的就是最热门10个查询串。

百度面试题：将query按照出现的频度排序（10个1G大小的文件）。有10个
文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的
query都可能重复。如何按照query的频度排序？
网上给出的答案：
1）读取10个文件，按照hash(query)%10的结果将query写到对应的10个文件
（file0,file1....file9）中，这样的10个文件不同于原先的10个文件。这样我们就有了10个
大小约为1G的文件。任意一个query只会出现在某个文件中。
2）对于1）中获得的10个文件，分别进行如下操作
      -  利用hash_map（query，query_count）来统计每个query出现的次数。
      -  利用堆排序算法对query按照出现次数进行排序。
      -  将排序好的query输出的文件中。
     这样我们就获得了10个文件，每个文件中都是按频率排序好的query。
3）对2）中获得的10个文件进行归并排序，并将最终结果输出到文件中。
注：如果内存比较小，在第1）步中可以增加文件数。

统计外站的搜索关键词的词频

    通过外站的链接主要是百度，谷歌，soso等，每天都有通过记录在日志文件中，每天会运
行程序进行统计。
每天产生有10多个文件，每个文件1G左右，  每个文件的每一行都存放的是用户的query，
每个文件的query 都可能重复。要按照解析query中的关键词，并对统计其频度，取出搜索
次数最多的前1000个关键词。

第一次直接遍历所有文件并按照Map<String,Integer>方式来统计，统计差不多共有四千万条


记录，词也有一百万多个，最后排序实现。方法简单，但也有很大的缺点，占用的内存太大，
可能会将服务器弄垮掉。
*/
