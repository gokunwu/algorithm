
#if 0

1、设rand（s，t）返回[s,t]之间的随机小数，利用该函数在一个半径为R的圆内
找随机n个点，并给出时间复杂度分析。

void GetNPointsInCircle(int R, int n)
{
    for (int i=0; i<n; i++)
    {
        float x = rand(-R, R);
        float y = rand(-sqrt(R*R - x*x), sqrt(R*R - x*x));
        //  也可以用极坐标表示

        printf("%f,%f\t", x,y);
    }
}
极坐标思路：
在半径为R的圆内找随机的n个点，既然是找点，那么就需要为其建立坐标系，如果建立
平面直角坐标系，以圆心为原点，建立半径为R的圆的直角坐标系。要使随机的点在圆内，
则必须使其所找的点  point 的x，y坐标的绝对值小于R，问题转化为：随机的找n个圆内
的点，使其x，y坐标的绝对值均小于R。这里以x为例，  首先  x 应满足  -R<= x <= R；   y
同理。这样产生的点均在以圆心为中心，边长为2R的正放形内，需要另外判断其距离R的
值。本文介绍采用极坐标的形式，建立圆的极坐标系，则圆内的任意一点满足 P(ρ,θ)（用ρ
表示线段OP的长度，θ表示从Ox到OP的角度angle），此时问题转化为：找一点，使其
到圆心的距离OP大于等于0 小于R，极角大于等于0 小于360，则OP=rand(0, R) ，当  OP==
R 时重新寻找，angle = rand(0,360) ，当angle==360时，重新寻找。每找到一个点p，将其
与之前所找到的所有点进行比较，若重合，则继续寻找，否则将其加入到已找到的点集合中，
直到找到n个点。
[cpp] view plaincopyprint?
1.  存放点的数据结构
2.  typedef struct Point{
3.  double r;
4.  double angle;
5.  }Point;


6.  算法流程：
7.  for( i=n ; i >0; i--)
8.     产生 p.r = rand(0,R)，且p.r != R
9.     产生 p.rangle = rand(0,360) ,且 p.rangle != 360
10.     遍历所有产生的点，若 p 已经存在，则重新生成该点
11.     否则将其加入到产生的点集合中
[cpp] view plaincopyprint?
1.  存放点的数据结构
2.  typedef struct Point{
3.  double r;
4.  double angle;
5.  }Point;
6.  算法流程：
7.  for( i=n ; i >0; i--)
8.     产生 p.r = rand(0,R)，且p.r != R
9.     产生 p.rangle = rand(0,360) ,且 p.rangle != 360
10.     遍历所有产生的点，若 p 已经存在，则重新生成该点
11.     否则将其加入到产生的点集合中
生成第n个点，需要先遍历前n-1个点，时间复杂度为O(n)，故生成n个点的时间复杂度为
O(n^2)

2、为分析用户行为，系统常需存储用户的一些query，但因query非常多，故系
统不能全存，设系统每天只存m个query，现设计一个算法，对用户请求的query
进行随机选择m个，请给一个方案，使得每个query被抽中的概率相等，并分析
之，注意：不到最后一刻，并不知用户的总请求量。
蓄水池抽样问题
随机抽样问题表示如下：
要求从N个元素中随机的抽取k个元素，其中N无法确定。
这种应用的场景一般是数据流的情况下，由于数据只能被读取一次，而且数据量很大，并不
能全部保存，因此数据量N是无法在抽样开始时确定的；但又要保持随机性，于是有了这
个问题。所以搜索网站有时候会问这样的问题。


【解决】
解决方案就是蓄水库抽样（reservoid sampling）。
引言：众所周知，想要面试一个统计学家和软件工程师的合体――数据工程师――是件很难的事情。我在面试中常使用的方法是：提出即需要算法设计，又需要一些概率论知识的问题，来考察面试者的功底。下面就是在硅谷非常流行的例子：

“给出一个数据流，这个数据流的长度很大或者未知。并且对该数据流中数据只能访问一次。请写出一个随机选择算法，使得数据流中所有数据被选中的概率相等。”

当面对这样一个问题的时候，我们首先应该做的是：镇静。你的面试官并没有玩你，相反他可能特别想雇你。他可能正在为无尽的分析请求烦恼，他的ETL流水线已经不在工作，已有的机器学习模型也不再适合。他正想要你这样一个聪明人进来帮忙，他希望你答出来。

第二件要做的事情是：不要在没有深入思考的情况下盲目作答。假设你的面试官读过Daniel Tunkelang的关于数据工程师的面试建议，那么这个面试题很可能就是他工作中实际遇到的问题。所以如果像下面一样随便回答，很可能会令你的面试官失望。

“我会首先将输入存到一个列表中，统计出数据流中数据的个数，在读取结束之后随机选取一个”（大哥， 你没看见题目已经说了，数据流长度很大或者未知么，不怕你的内存装不下？）

第三件要做的事情是：从小例子开始分析。大部分的人都更容易解决具体问题（而不是抽象问题），最开始你设计的小例子可能和最后的问题之间相去甚远，但是却能启发你对问题的理解，给你灵感。



蓄水池算法

如前面所说，对这个问题我们首先从最简单的例子出发：数据流只有一个数据。我们接收数据，发现数据流结束了，直接返回该数据，该数据返回的概率为1。看来很简单，那么我们试试难一点的情况：假设数据流里有两个数据。

我们读到了第一个数据，这次我们不能直接返回该数据，因为数据流没有结束。我们继续读取第二个数据，发现数据流结束了。因此我们只要保证以相同的概率返回第一个或者第二个数据就可以满足题目要求。因此我们生成一个0到1的随机数R,如果R小于0.5我们就返回第一个数据，如果R大于0.5，返回第二个数据。

接着我们继续分析有三个数据的数据流的情况。为了方便，我们按顺序给流中的数据命名为1、2、3。我们陆续收到了数据1、2和前面的例子一样，我们只能保存一个数据，所以必须淘汰1和2中的一个。应该如何淘汰呢？不妨和上面例子一样，我们按照二分之一的概率淘汰一个，例如我们淘汰了2。继续读取流中的数据3，发现数据流结束了，我们知道在长度为3的数据流中，如果返回数据3的概率为1/3,那么才有可能保证选择的正确性。也就是说，目前我们手里有1,3两个数据，我们通过一次随机选择，以1/3的概率留下数据3，以2/3的概率留下数据1.那么数据1被最终留下的概率是多少呢？

数据1被留下：（1/2）*(2/3) = 1/3
数据2被留下概率：（1/2）*(2/3) = 1/3
数据3被留下概率：1/3
这个方法可以满足题目要求，所有数据被留下返回的概率一样！

因此，我们做一下推论：假设当前正要读取第n个数据，则我们以1/n的概率留下该数据，否则留下前n-1个数据中的一个。以这种方法选择，所有数据流中数据被选择的概率一样。简短的证明：假设n-1时候成立，即前n-1个数据被返回的概率都是1/n-1,当前正在读取第n个数据，以1/n的概率返回它。那么前n-1个数据中数据被返回的概率为：(1/(n-1))*((n-1)/n)= 1/n，假设成立。

这就是所谓的蓄水池抽样算法。它在分析一些大数据集的时候非常有用。你可以在这里找到Greg写的关于蓄水池抽样的算法介绍。本文后面会介绍一下在Cloudera ML中使用的两种：分布式蓄水池抽样和加权分布式蓄水池抽样。

（注：Cloudera ML是基于hadoop的数据分析和挖掘开源项目）



蓄水池抽样在Cloudera ML上的应用

分布式蓄水池抽样是Greg讨论的第一种算法。可以从前面的讨论中发现，基本的蓄水池抽样要求对数据流进行顺序读取。要进行容量为k的分布式蓄水池抽样（前面讨论的容量都为1）我们使用mapreduce 模拟sql中的ORDER BY RAND (随机抽取)。对于集合中的每一个元素，都产生一个0-1的随机数，之后选取随机值最大的前k个元素。这种方法在对大数据集进行分层抽样的时候非常管用。这里每一个分层都都是一些分类变量如性别，年龄，地理信息等的组合。注意如果输入的数据集分布极端的不均匀，那么抽样可能不能覆盖到所有的层级。为了对每种分类的组合进行抽样，cloudera ML 提供了sample命令，它可以操作纯文本或者hive中的表。

第二个算法更加好玩：加权分布式蓄水池抽样。这里集合中的数据是有权重的，算法希望数据被抽样选中的概率和该数据的权重成比例。实际上这个问题之前并不一定有解，直到2005年pavlos efraimidis和paul spirakis的论文《weighted random sampling with a reservoir》。他们的解法既简单又优雅，基本思想和上面的分布式蓄水池抽样一致：对于每个数据计算一个0-1的值R，并求r的n次方根作为该数据的新的R值。这里的n就是该数据的权重。最终算法返回前k个R值最高的数据然后返回。根据计算规则，权重越大的数据计算所得的R值越接近1，所以越有可能被返回。

在cloudera ML项目中，为了更好地使用k-means++算法（K-均值++算法），我们会首先使用加权的蓄水池抽样算法对输入数据进行抽样。ksketch命令会为k-means++算法进行初始化C在输入数据上进行迭代操作，选择样本抽样。每次选取过程，数据被选入样本的概率和该数据与当前样本中最短距离节点的距离成比例。通过使用加权的蓄水池抽样算法，只需扫描数据一遍就能决定样本组成（一般方法需要首先遍历一次以计算出聚类的总代价，之后第二次遍历根据第一次的计算结果进行样本选择）。



要读的一些书目

很多有趣的算法都不止对写分布式文件系统或者搜索引擎的工程师有用，它们有时对于大规模数据分析和一些统计问题也特别有帮助。接下来，我会再写几篇关于算法博客。但在这之前我的说，高德纳老爷子的书常读常新，大家先去看看《计算机程序设计艺术》上面的算法吧~


C++ STL中vector的相关问题：
    （1）、调用push_back时，其内部的内存分配是如何进行的？
    （2）、调用clear时，内部是如何具体实现的？若想将其内存释放，该如何操作？

vector的工作原理是系统预先分配一块CAPACITY大小的空间，当插入的数据超过这个空间的时候，这块空间会让某种方式扩展，但是你删除数据的时候，它却不会缩小。
  vector为了防止大量分配连续内存的开销，保持一块默认的尺寸的内存，clear只是清数据了，未清内存，因为vector的capacity容量未变化，系统维护一个的默认值。

有什么方法可以释放掉vector中占用的全部内存呢?

标准的解决方法如下
template < class T >
void ClearVector( vector< T >& vt )
{
vector< T > vtTemp;
veTemp.swap( vt );
}

  事实上，vector根本就不管内存，它只是负责向内存管理框架acquire/release内存，内存管理框架如果发现内存不够了，就malloc，但是当vector释放资源的时候(比如destruct), stl根本就不调用free以减少内存，因为内存分配在stl的底层：stl假定如果你需要更多的资源就代表你以后也可能需要这么多资源(你的list, hashmap也是用这些内存)，所以就没必要不停地malloc/free。如果是这个逻辑的话这可能是个trade-off

  一般的STL内存管理器allocator都是用内存池来管理内存的，所以某个容器申请内存或释放内存都只是影响到内存池的剩余内存量，而不是真的把内存归还给系统。这样做一是为了避免内存碎片，二是提高了内存申请和释放的效率――不用每次都在系统内存里寻找一番。
#endif // 0
